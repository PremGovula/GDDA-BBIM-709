{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtoAFm6f7dDd",
        "outputId": "888dc048-ec30-4b08-969f-4316c0ba435d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- InvoiceNo: string (nullable = true)\n",
            " |-- StockCode: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- InvoiceDate: date (nullable = true)\n",
            " |-- UnitPrice: double (nullable = true)\n",
            " |-- CustomerID: double (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- CustomerName: string (nullable = true)\n",
            " |-- TotalSales: double (nullable = true)\n",
            " |-- Anomaly: integer (nullable = true)\n",
            "\n",
            "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+----------------+----------+-------+\n",
            "|InvoiceNo|StockCode|         Description|Quantity|InvoiceDate|UnitPrice|CustomerID|       Country|    CustomerName|TotalSales|Anomaly|\n",
            "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+----------------+----------+-------+\n",
            "|   536460|    22926|IVORY GIANT GARDE...|       4| 2024-06-16|     5.95|   14849.0|United Kingdom|     Anna Miller|      23.8|      0|\n",
            "|   536796|    22561|WOODEN SCHOOL COL...|       1| 2024-06-17|     1.65|   15574.0|United Kingdom|  Anthony Lester|      1.65|      0|\n",
            "|   536601|    22633|HAND WARMER UNION...|       6| 2024-06-17|     1.85|   17850.0|United Kingdom|Timothy Williams|      11.1|      0|\n",
            "|   536627|    22783|SET 3 WICKER OVAL...|       1| 2024-06-17|    19.95|   15658.0|United Kingdom|  Sarah Thompson|     19.95|      0|\n",
            "|   536635|    21868|POTTING SHED TEA MUG|      12| 2024-06-17|     1.25|   15955.0|United Kingdom|  Joyce Phillips|      15.0|      0|\n",
            "+---------+---------+--------------------+--------+-----------+---------+----------+--------------+----------------+----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder.appName(\"ClassificationModel\").getOrCreate()\n",
        "\n",
        "# Load your CSV file\n",
        "df = spark.read.csv(\"daily_aggregation2.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Show schema and few rows\n",
        "df.printSchema()\n",
        "df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "i-K8hiFJ7psQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Drop rows with nulls (optional)\n",
        "df = df.na.drop(subset=[\"Anomaly\", \"Quantity\", \"UnitPrice\", \"TotalSales\"])\n",
        "\n",
        "# Define features and label\n",
        "feature_cols = [\"Quantity\", \"UnitPrice\", \"TotalSales\"]\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
        "\n",
        "data = assembler.transform(df).select(col(\"features\"), col(\"Anomaly\").alias(\"label\"))\n",
        "data.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6uGKBAz7eJR",
        "outputId": "c1f81714-0ef0-405d-edc0-b8999ecd0841"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+\n",
            "|         features|label|\n",
            "+-----------------+-----+\n",
            "|  [4.0,5.95,23.8]|    0|\n",
            "|  [1.0,1.65,1.65]|    0|\n",
            "|  [6.0,1.85,11.1]|    0|\n",
            "|[1.0,19.95,19.95]|    0|\n",
            "| [12.0,1.25,15.0]|    0|\n",
            "+-----------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n"
      ],
      "metadata": {
        "id": "ni0R1w7Y7-qF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "lr_model = lr.fit(train_data)\n"
      ],
      "metadata": {
        "id": "Tl3ZXE4D8BJ0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = lr_model.transform(test_data)\n",
        "predictions.select(\"features\", \"label\", \"prediction\", \"probability\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mgnT0gN8DBV",
        "outputId": "b22c9107-1ca2-4c06-ab6d-1d9195f63049"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+----------+-----------+\n",
            "|            features|label|prediction|probability|\n",
            "+--------------------+-----+----------+-----------+\n",
            "|[-144.0,0.72,-103...|    0|       0.0|  [1.0,0.0]|\n",
            "| [-48.0,4.95,-237.6]|    0|       0.0|  [1.0,0.0]|\n",
            "|  [-36.0,0.85,-30.6]|    0|       0.0|  [1.0,0.0]|\n",
            "|  [-12.0,2.55,-30.6]|    0|       0.0|  [1.0,0.0]|\n",
            "|    [-4.0,1.95,-7.8]|    0|       0.0|  [1.0,0.0]|\n",
            "+--------------------+-----+----------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f\"AUC: {auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdoQhkRc8E9s",
        "outputId": "54c1e779-e3c2-4236-de9d-5b0e2f0f42a0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Accuracy\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator_acc.evaluate(predictions)\n",
        "\n",
        "# Precision (weighted)\n",
        "evaluator_prec = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
        "precision = evaluator_prec.evaluate(predictions)\n",
        "\n",
        "# Recall (weighted)\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "recall = evaluator_recall.evaluate(predictions)\n",
        "\n",
        "# F1 Score (weighted)\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "f1 = evaluator_f1.evaluate(predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P8ZnLdr8I0B",
        "outputId": "48ac20db-be26-4f52-ad4c-85a9c2c91717"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "lr_model = lr.fit(train_data)\n"
      ],
      "metadata": {
        "id": "RwKq838m8W60"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = lr_model.transform(test_data)\n",
        "predictions.select(\"label\", \"prediction\").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ecovs2BAyl6",
        "outputId": "acbe3832-099b-4921-b75d-0d238914eba9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+\n",
            "|label|prediction|\n",
            "+-----+----------+\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = lr_model.transform(test_data)\n",
        "predictions.select(\"label\", \"prediction\").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaiokajeA1Jc",
        "outputId": "1f1b1440-4533-4666-bd1b-502ff62be6bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+\n",
            "|label|prediction|\n",
            "+-----+----------+\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "|    0|       0.0|\n",
            "+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "accuracy = evaluator.setMetricName(\"accuracy\").evaluate(predictions)\n",
        "precision = evaluator.setMetricName(\"weightedPrecision\").evaluate(predictions)\n",
        "recall = evaluator.setMetricName(\"weightedRecall\").evaluate(predictions)\n",
        "f1 = evaluator.setMetricName(\"f1\").evaluate(predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRa6Kz1xA4S-",
        "outputId": "7ab5435b-3032-4e2a-df38-9fbef0c8c870"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1 Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KweFN4fwA7HE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}